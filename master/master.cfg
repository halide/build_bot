# -*- python -*-
# ex: set syntax=python:

from buildbot.worker import Worker
from buildbot.config import BuilderConfig
from buildbot.changes.gitpoller import GitPoller
from buildbot.changes.github import GitHubPullrequestPoller
from buildbot.schedulers.basic import SingleBranchScheduler
from buildbot.schedulers.forcesched import ForceScheduler
from buildbot.schedulers.trysched import Try_Userpass
from buildbot.plugins import util
from collections import defaultdict
from functools import partial
from os.path import isfile
from twisted.internet import defer

# At any given time, we test (at least) 3 LLVM versions:
# - the current trunk (changes daily)
# - the most recent release (expected to be stable)
# - an older release (expected to be stable)
#
# the branches that correspond to these will rotate as new versions
# are released, but the underlying test logic should not need changing

LLVM_TRUNK_BRANCH = 'master'
LLVM_RELEASE_BRANCH = 'release/10.x'
LLVM_OLD_BRANCH = 'release/9.x'

# Map the branchnames to the "old" naming style, for continuity
_TO_NAME = {
    LLVM_TRUNK_BRANCH: 'trunk',
    LLVM_RELEASE_BRANCH: '1000',
    LLVM_OLD_BRANCH: '900',
}


def to_name(llvm_branch):
    return _TO_NAME[llvm_branch]

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# BUILDWORKERS

import os

# The 'workers' list defines the set of recognized buildworkers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.

password = open('halide_bb_pass.txt').read().strip()

workers = []
worker_suffixes = ['-1', '-2', '-3', '-4', '-5', '-6']
for sfx in worker_suffixes:
    workers.append(Worker('linux-worker' + sfx,     password, max_builds=2))
    workers.append(Worker('mac-worker' + sfx,       password, max_builds=2))
    workers.append(Worker('arm32-linux-worker' + sfx, password, max_builds=1))
    workers.append(Worker('arm64-linux-worker' + sfx, password, max_builds=1))
    workers.append(Worker('win-worker' + sfx,       password, max_builds=1))

c['workers'] = workers

# 'protocols' contains information about protocols which master will use for
# communicating with workers.
# You must define at least 'port' option that workers could connect to your master
# with this protocol.
# 'port' must match the value configured into the buildworkers (with their
# --master option)
c['protocols'] = {'pb': {'port': 9990}}

# LOCKS

# Performance testing requires exclusive use of a worker

# Compute-intensive build steps will grab this lock in reader
# mode. The performance test will grab it in exclusive mode.
performance_lock = util.WorkerLock("performance_lock",
                                   maxCount=9999)

# CHANGESOURCES

# the 'change_source' setting tells the buildmaster how it should find out
# about source code changes.  Here we point to the buildbot clone of halide.

c['change_source'] = []

token = open('github_token.txt').read().strip()

c['change_source'].append(GitPoller(
    repourl='git://github.com/halide/Halide.git',
    workdir='gitpoller-halide-workdir',
    branch='master',
    pollInterval=60 * 5,  # Check Halide master every five minutes
    pollAtLaunch=True))


def pr_filter(pr):
    # Auto test anything in the halide master repo
    # print("Considering PR: ", pr['title'], pr['html_url'])
    # for (k, v) in pr.items():
    #    print(k, v)
    repo = pr['head']['repo']
    result = repo is not None and repo['full_name'] == 'halide/Halide'
    reviewers = pr['requested_reviewers']
    if reviewers is not None:
        for r in reviewers:
            result = result or (r['login'] == 'halidebuildbots')
    # Any PR labeled with 'skip_buildbots' should be skipped
    labels = pr['labels']
    if labels is not None:
        for l in labels:
            if l['name'] == 'skip_buildbots':
                result = False
    # print("Filter result: ", result)
    # print("PR: ", pr['title'], pr['html_url'], ' => ', result)
    return result

c['change_source'].append(GitHubPullrequestPoller(
    owner='halide',
    repo='Halide',
    token=token,
    pullrequest_filter=pr_filter,
    pollInterval=60 * 5,  # Check Halide PRs every five minutes
    pollAtLaunch=True))

c['change_source'].append(GitPoller(
    repourl='https://github.com/llvm/llvm-project.git',
    workdir='gitpoller-llvm-workdir',
    branch=LLVM_TRUNK_BRANCH,
    pollInterval=60 * 60 * 24,  # Only check llvm once every 24 hours
    pollAtLaunch=True))

# CODEBASES

all_repositories = {
    r'git://github.com/halide/Halide.git': 'halide',
    'https://github.com/halide/Halide.git': 'halide',
    r'git://github.com/llvm/llvm-project.git': 'llvm',
    'https://github.com/llvm/llvm-project.git': 'llvm',
}


def codebase_generator(chdict):
    repo = chdict['repository']
    if repo in all_repositories:
        return all_repositories[repo]
    else:
        return 'halide'

c['codebaseGenerator'] = codebase_generator

# BUILDERS

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which workers can execute them.  Note that any particular build will
# only take place on one worker.

from buildbot.process.factory import BuildFactory
from buildbot.steps.source.git import Git
from buildbot.steps.shell import ShellCommand
from buildbot.steps.cmake import CMake
from buildbot.steps.worker import RemoveDirectory
from buildbot.steps.transfer import FileUpload
from buildbot.steps.worker import MakeDirectory
from buildbot.steps.master import MasterShellCommand
from buildbot.process.properties import Property
from buildbot.process.properties import renderer
from buildbot.process.properties import Interpolate


def get_builddir_subpath(subpath):
    return util.Interpolate('%(prop:builddir)s/' + subpath)


def get_llvm_source_path(*subpaths):
    return get_builddir_subpath(os.path.join('llvm-project', *subpaths))


def get_llvm_build_path(config, *subpaths):
    return get_builddir_subpath(os.path.join('llvm-build-%s' % config, *subpaths))


def get_llvm_install_path(config, *subpaths):
    return get_builddir_subpath(os.path.join('llvm-install-%s' % config, *subpaths))


def get_halide_source_path(*subpaths):
    return get_builddir_subpath(os.path.join('halide', *subpaths))


def get_halide_build_path(config, *subpaths):
    return get_builddir_subpath(os.path.join('halide-%s' % config, *subpaths))


def add_get_source_steps(factory, llvm_branch):

    assert llvm_branch in [LLVM_TRUNK_BRANCH, LLVM_RELEASE_BRANCH, LLVM_OLD_BRANCH]

    factory.addStep(Git(name='Get Halide master',
                        locks=[performance_lock.access('counting')],
                        codebase='halide',
                        workdir=get_halide_source_path(),
                        repourl='git://github.com/halide/Halide.git',
                        branch='master',
                        mode='incremental'))

    factory.addStep(Git(name='Get LLVM ' + to_name(llvm_branch),
                        locks=[performance_lock.access('counting')],
                        codebase='llvm',
                        workdir=get_llvm_source_path(),
                        repourl='https://github.com/llvm/llvm-project.git',
                        branch=llvm_branch,
                        mode='incremental'))


@renderer
def get_distrib_name(props):
    rev = props.getProperty('got_revision')['halide']
    builder = props.getProperty('buildername')
    if builder.startswith('win'):
        suffix = '.zip'
    else:
        suffix = '.tgz'
    # Always upload to /home/abadams/artifacts -- regardless of user --
    # since that's there the public-facing webpage looks
    return '/home/abadams/artifacts/halide-' + builder + '-' + rev + suffix


def get_cmake_generator(os):
    if os.startswith('win'):
        # if '-32' in os:    # VS2017
        #     return 'Visual Studio 15'
        # else:
        #     assert '-64' in os
        #     return 'Visual Studio 15 Win64'
        return 'Visual Studio 16 2019'
    else:
        return 'Ninja'


def get_cmake_options(os):
    options = []
    if os.startswith('win'):
        # options.append('-Thost=x64')   # VS2017
        options.extend(['-T', 'host=x64'])
        if '-32' in os:
            options.extend(['-A', 'Win32'])
        else:
            options.extend(['-A', 'x64'])
    return options


def get_halide_cmake_definitions(os, config, hl_target='host'):
    cmake_definitions = {
        'Clang_DIR': get_llvm_install_path(config, 'lib/cmake/clang'),
        'CMAKE_BUILD_TYPE': config,
        'HL_TARGET': hl_target,
        'LLVM_DIR': get_llvm_install_path(config, 'lib/cmake/llvm'),
    }

    # The linux and arm linux buildbots have ccache installed
    # (TODO: can install on mac if we update XCode there)
    if 'linux' in os:
        cmake_definitions['CMAKE_C_COMPILER_LAUNCHER'] = 'ccache'
        cmake_definitions['CMAKE_CXX_COMPILER_LAUNCHER'] = 'ccache'

    if os.startswith('win-32'):
        cmake_definitions['Python3_ROOT_DIR'] = r'C:/Program Files (x86)/Python38-32'

    if os.startswith('win'):
        cmake_definitions['CMAKE_TOOLCHAIN_FILE'] = r'C:/vcpkg/scripts/buildsystems/vcpkg.cmake'

    # Armbots don't have Python configured, so python bindings won't build
    if os.startswith('arm'):
        cmake_definitions['WITH_PYTHON_BINDINGS'] = 'OFF'

    # TODO: buildbots + config need love to make 32-bit Python work properly,
    # just disable the testing for now
    if os.startswith('linux-32'):
        cmake_definitions['WITH_PYTHON_BINDINGS'] = 'OFF'

    return cmake_definitions


def get_cmake_build_command(os, config, build_dir, target=None):
    cmd = ['cmake',
           '--build', build_dir,
           '--config', config,
           '-j', get_build_parallelism(os)]
    if target:
        cmd.extend(['--target', target])
    return cmd


def get_llvm_cmake_definitions(os, config, llvm_branch):
    definitions = {
        'CMAKE_BUILD_TYPE': config,
        'CMAKE_INSTALL_PREFIX': get_llvm_install_path(config),
        'LLVM_BUILD_32_BITS': ('ON' if '-32' in os else 'OFF'),
        'LLVM_ENABLE_ASSERTIONS': 'ON',
        'LLVM_ENABLE_LIBXML2': 'OFF',
        'LLVM_ENABLE_PROJECTS': 'clang;lld',
        'LLVM_ENABLE_RTTI': 'ON',
        'LLVM_ENABLE_TERMINFO': 'OFF',
        'LLVM_TARGETS_TO_BUILD': 'X86;ARM;NVPTX;AArch64;Mips;Hexagon;PowerPC' + (';WebAssembly' if llvm_branch == LLVM_TRUNK_BRANCH else ''),
    }

    if os.startswith('linux-32'):
        definitions['CMAKE_FIND_ROOT_PATH'] = '/usr/lib/i386-linux-gnu'
        definitions['CMAKE_FIND_ROOT_PATH_MODE_LIBRARY'] = 'ONLY'

    # This disables an XCode setting that can get enabled by default
    # when assertions are enabled, but only if your XCode install has
    # certain frameworks installed; we want it disabled, as it prevents
    # prebuilt libraries from working properly with XCode 9.x.
    if os.startswith('mac'):
        definitions['LLVM_ENABLE_SUPPORT_XCODE_SIGNPOSTS'] = 'FORCE_OFF'

    return definitions


def get_env(os, config):
    env = {'LLVM_CONFIG': get_llvm_build_path(config, 'bin/llvm-config')}

    cxx = 'c++'
    cc = 'cc'
    ld = 'ld'

    if os.startswith('linux'):
        if '-gcc53' in os:
            cc = 'gcc-5.3'
            cxx = 'g++-5.3'
        else:
            assert(False)

        ld = 'ld'
        if '-32' in os:
            cxx += ' -m32'
            cc += ' -m32'
            ld += ' -melf_i386'
    elif os.startswith('mac'):
        if '-32' in os:
            cxx += ' -m32'
            cc += ' -m32'

    # The linux and arm linux buildbots have ccache installed
    # (TODO: can install on mac if we update XCode there)
    if 'linux' in os:
        cxx = 'ccache ' + cxx
        cc = 'ccache ' + cc

    env['CXX'] = cxx
    env['CC'] = cc
    env['LD'] = ld

    if os.startswith('linux'):
            # Environment variables for testing Hexagon DSP
        env['HL_HEXAGON_TOOLS'] = '/usr/local/hexagon'
        env['HL_HEXAGON_SIM_REMOTE'] = '${PWD}/worker/' + os + \
            '-trunk/halide/src/runtime/hexagon_remote/bin/v62/hexagon_sim_remote'
        env['HL_HEXAGON_SIM_CYCLES'] = '1'
        env['LD_LIBRARY_PATH'] = '${LD_LIBRARY_PATH}:${PWD}/worker/' + os + \
            '-trunk/halide/src/runtime/hexagon_remote/bin/host:/usr/local/hexagon/lib/iss'
    elif os.startswith('mac'):
        # Environment variable for turning on Metal API validation
        # This will have no effect on CPU testing, just Metal testing
        env['METAL_DEVICE_WRAPPER_TYPE'] = '1'

    return env


def get_build_parallelism(os):
    # Standard wisdom is (nproc+2)
    if os.startswith('linux'):
        # TODO: our Linux bots also have 12 cores; this seems maybe too high?
        return 8
    elif os.startswith('mac'):
        # MacBot has 32GB and 6/12 core Xeon. We allow two builds at
        # once so set threads = (12/2)+2 == 8
        return 8
    elif os.startswith('win'):
        # WinBots have 6/12 cores but are very slow; let's try half the Mac
        return 4
    elif os.startswith('arm'):
        return 2
    else:
        return 1


def get_workers(os):
    if os.startswith('linux'):
        return ['linux-worker' + sfx for sfx in worker_suffixes]
    elif os.startswith('mac'):
        return ['mac-worker' + sfx for sfx in worker_suffixes]
    elif os.startswith('win'):
        return ['win-worker' + sfx for sfx in worker_suffixes]
    elif os.startswith('arm32-linux'):
        return ['arm32-linux-worker' + sfx for sfx in worker_suffixes]
    elif os.startswith('arm64-linux'):
        return ['arm64-linux-worker' + sfx for sfx in worker_suffixes]


def add_llvm_steps(factory, llvm_branch, os, configs, clean_rebuild):
    for config in configs:
        env = get_env(os, config)

        build_dir = get_llvm_build_path(config)
        install_dir = get_llvm_install_path(config)

        if clean_rebuild:
            factory.addStep(RemoveDirectory(dir=build_dir, haltOnFailure=False))
            factory.addStep(RemoveDirectory(dir=install_dir, haltOnFailure=False))

        factory.addStep(MakeDirectory(dir=build_dir, haltOnFailure=False))
        factory.addStep(MakeDirectory(dir=install_dir, haltOnFailure=False))

        factory.addStep(
            CMake(name='Configure LLVM %s' % config,
                  description='Configure LLVM %s' % config,
                  locks=[performance_lock.access('counting')],
                  haltOnFailure=True,
                  env=env,
                  workdir=build_dir,
                  path=get_llvm_source_path('llvm'),
                  generator=get_cmake_generator(os),
                  definitions=get_llvm_cmake_definitions(os, config, llvm_branch),
                  options=get_cmake_options(os)))

        factory.addStep(
            ShellCommand(name='Build LLVM %s' % config,
                         description='Build LLVM %s' % config,
                         locks=[performance_lock.access('counting')],
                         haltOnFailure=True,
                         workdir=build_dir,
                         env=env,
                         command=get_cmake_build_command(os, config, build_dir, target='install')))


def add_halide_cmake_build_steps(factory, llvm_branch, os, configs):
    for config in configs:
        env = get_env(os, config)

        # Always do a clean build for Halide
        source_dir = get_halide_source_path()
        build_dir = get_halide_build_path(config)
        factory.addStep(RemoveDirectory(dir=build_dir, haltOnFailure=False))
        factory.addStep(MakeDirectory(dir=build_dir, haltOnFailure=False))

        factory.addStep(CMake(name='Configure Halide %s' % config,
                              description='Configure Halide %s' % config,
                              locks=[performance_lock.access('counting')],
                              haltOnFailure=True,
                              workdir=build_dir,
                              env=env,
                              path=source_dir,
                              generator=get_cmake_generator(os),
                              definitions=get_halide_cmake_definitions(os, config),
                              options=get_cmake_options(os)))

        factory.addStep(
            ShellCommand(name='Build Halide %s' % config,
                         description='Build Halide %s' % config,
                         locks=[performance_lock.access('counting')],
                         haltOnFailure=True,
                         workdir=build_dir,
                         env=env,
                         command=get_cmake_build_command(os, config, build_dir)))


# Return a dict with halide-targets as the keys, and a list of test-labels for each value.
def get_test_labels(os, llvm_branch):
    targets = defaultdict(list)

    targets['host'].extend(['internal', 'correctness', 'generator',
                            'error', 'warning', 'apps', 'performance'])

    # TODO: some JIT+generator tests are failing on arm32; disable for now
    # pending fixes (see https://github.com/halide/Halide/issues/4940)
    if os.startswith('arm32'):
        targets['host'].remove('internal')
        targets['host'].remove('generator')

    # The armbots aren't equipped to use python.
    # TODO: buildbots + config need love to make 32-bit Python work properly,
    # just disable the testing for now
    if not os.startswith('arm') and not os.startswith('linux-32'):
        targets['host'].extend(['python'])

    if os.startswith('linux-32-gcc53'):
        # Also test without sse 4.1
        targets['x86-32'].extend(['correctness'])

    if os.startswith('linux-64-gcc53') or os.startswith('mac-64'):
        # extended cpu/gpu tests
        targets['x86-64'].extend(['correctness'])
        targets['x86-64-sse41'].extend(['correctness'])

    if os.startswith('linux-64-gcc53'):
        # The linux build-bots have an nvidia card
        targets['host-cuda'].extend(['correctness', 'generator', 'apps'])
        targets['host-opencl'].extend(['correctness', 'generator', 'apps'])
        targets['host-cuda-opencl'].extend(['correctness_multi_gpu'])

    if os.startswith('mac-64'):
        # test metal on OS X
        targets['host-metal'].extend(['correctness', 'generator', 'apps'])

    if os.startswith('win-64'):
        targets['host-cuda'].extend(['correctness', 'generator', 'apps'])
        targets['host-opencl'].extend(['correctness', 'generator', 'apps'])
        # TODO: temporarily disabled due to https://github.com/halide/Halide/issues/3909
        # targets['host-d3d12compute'].extend(['correctness', 'generator', 'apps'])

    if os.startswith('linux-64-gcc53') and llvm_branch == LLVM_TRUNK_BRANCH:
        # Also test hexagon using the simulator
        targets['host-hvx_128'].extend(['correctness', 'generator', 'apps'])
        targets['host-hvx_64'].extend(['correctness', 'generator', 'apps'])

    return targets

# Return true if the test label (or single-test name) is 'time critical' and must
# be run with an exclusive lock on the buildbot (typically, performance tests)


def is_time_critical_test(test):
    return test in ['performance']


def add_halide_cmake_test_steps(factory, llvm_branch, os, configs):
    base_env = {
        # Current NVidia drivers on our Windows buildbots can corrupt their own
        # cache, leading to many spurious failures. Disable the cache
        # for now, pending NVidia investigation.
        'CUDA_CACHE_DISABLE': '1',

        # We don't ever want an Abort, Rerty, Ignore dialog in our tests
        'HL_DISABLE_WINDOWS_ABORT_DIALOG': '1'
    }

    parallelism = get_build_parallelism(os)

    labels = get_test_labels(os, llvm_branch)

    for config in configs:
        source_dir = get_halide_source_path()
        build_dir = get_halide_build_path(config)

        # Since we need to do at least a partial rebuild for each different target,
        # we want to group things by target. Do host first, followed by a key-sorted
        # order, to ensure predictability.
        keys = list(labels.keys())
        keys.remove('host')
        keys.sort()
        keys.insert(0, 'host')

        for hl_target in keys:
            env = base_env.copy()
            env['HL_TARGET'] = hl_target
            env['HL_JIT_TARGET'] = hl_target

            factory.addStep(
                CMake(name='Reconfigure for HL_TARGET=%s' % hl_target,
                      description='Reconfigure for HL_TARGET=%s' % hl_target,
                      locks=[performance_lock.access('counting')],
                      haltOnFailure=True,
                      env=env,
                      workdir=build_dir,
                      path=source_dir,
                      generator=get_cmake_generator(os),
                      definitions=get_halide_cmake_definitions(os, config, hl_target=hl_target),
                      options=get_cmake_options(os)))

            factory.addStep(
                ShellCommand(name='Rebuild for HL_TARGET=%s' % hl_target,
                             description='Rebuild Halide for HL_TARGET=%s' % hl_target,
                             locks=[performance_lock.access('counting')],
                             haltOnFailure=True,
                             workdir=build_dir,
                             env=env,
                             command=get_cmake_build_command(os, config, build_dir)))

            test_labels = labels[hl_target]

            # TODO: buildbots + config need love to make 32-bit Python work properly,
            # just disable the testing for now
            if os.startswith('arm') or os.startswith('linux-32'):
                if 'python' in test_labels:
                    test_labels.remove('python')

                # TODO: some of the apps require python, so we must skip them for now also
                if 'apps' in test_labels:
                    test_labels.remove('apps')

            parallel_test_labels = [
                test for test in test_labels if not is_time_critical_test(test)]
            exclusive_test_labels = [test for test in test_labels if is_time_critical_test(test)]

            if len(parallel_test_labels):
                test_set = '|'.join(parallel_test_labels)
                # Note that we pass cmd as a single string deliberately,
                # to avoid buildbot escaping issues with the | char
                cmd = ' '.join(['ctest',
                                '--build-config', config,
                                '--output-on-failure',
                                '--label-regex', '"%s"' % test_set,
                                '--parallel', '%d' % parallelism])
                factory.addStep(
                    ShellCommand(name='Test %s HL_TARGET=%s' % (test_set, hl_target),
                                 description='Test %s HL_TARGET=%s' % (test_set, hl_target),
                                 locks=[performance_lock.access('counting')],
                                 workdir=build_dir,
                                 env=env,
                                 timeout=3600,
                                 command=cmd))

            if len(exclusive_test_labels):
                test_set = '|'.join(exclusive_test_labels)
                # Note that we pass cmd as a single string deliberately,
                # to avoid buildbot escaping issues with the | char
                cmd = ' '.join(['ctest',
                                '--build-config', config,
                                '--output-on-failure',
                                '--label-regex', '"%s"' % test_set])
                factory.addStep(
                    ShellCommand(name='Test %s HL_TARGET=%s' % (test_set, hl_target),
                                 description='Test %s HL_TARGET=%s' % (test_set, hl_target),
                                 locks=[performance_lock.access('exclusive')],
                                 workdir=build_dir,
                                 env=env,
                                 timeout=3600,
                                 command=cmd))


def create_make_factory(os, llvm_branch):
    assert not os.startswith('win')

    configs = ['Release']
    for config in configs:
        env = get_env(os, config)
        make_threads = get_build_parallelism(os)
        build_dir = get_halide_build_path(config)

        factory = BuildFactory()

        add_get_source_steps(factory, llvm_branch)

        # TODO: we shouldn't need a clean rebuild anymore
        clean_llvm_rebuild = False  # (llvm_branch == LLVM_TRUNK_BRANCH)
        add_llvm_steps(factory, llvm_branch, os, configs, clean_llvm_rebuild)

        # Force a full rebuild of Halide every time
        factory.addStep(RemoveDirectory(dir=build_dir))

        targets = [('distrib', 'host'),
                   ('build_tests', 'host')]

        labels = get_test_labels(os, llvm_branch)
        for hl_target in list(labels.keys()):
            for label in labels[hl_target]:
                # TODO: buildbots + config need love to make 32-bit Python work properly,
                # just disable the testing for now
                if os.startswith('arm') or os.startswith('linux-32'):
                    if 'python' in label:
                        continue
                    # TODO: some of the apps require python, so we must skip them for now also
                    if 'apps' in label:
                        continue
                targets.append((label, hl_target))

        for (target, hl_target) in targets:
            target_env = env.copy()
            target_env['HL_TARGET'] = hl_target
            target_env['HL_JIT_TARGET'] = hl_target

            if is_time_critical_test(target):
                p = 1
                lock_mode = 'exclusive'
            else:
                p = make_threads
                lock_mode = 'counting'

            if target != 'distrib' and target != 'build_tests':
                target = 'test_%s' % target

            factory.addStep(ShellCommand(name='make ' + target,
                                         description=target + ' ' + hl_target,
                                         locks=[performance_lock.access(lock_mode)],
                                         workdir=build_dir,
                                         env=target_env,
                                         haltOnFailure=(target == 'distrib'),
                                         command=['make',
                                                  '-f', get_halide_source_path('Makefile'),
                                                  '-j', p,
                                                  target],
                                         timeout=3600))
            if target == 'distrib' and 'testbranch' not in os:
                factory.addStep(
                    FileUpload(workersrc='distrib/halide.tgz',
                               workdir=build_dir,
                               mode=0o644,
                               masterdest=get_distrib_name))

                factory.addStep(MasterShellCommand(
                    workdir='/home/abadams/artifacts',
                    command=['bash', '/home/abadams/build_bot_new/clean_artifacts.sh']))

    return factory

# TODO replace this with cmake package


def create_win_distro_factory(os, llvm_branch):
    assert os.startswith('win')

    factory = BuildFactory()
    add_get_source_steps(factory, llvm_branch)

    configs = ['Release', 'Debug']

    clean_llvm_rebuild = (llvm_branch == LLVM_TRUNK_BRANCH)
    add_llvm_steps(factory, llvm_branch, os, configs, clean_llvm_rebuild)

    add_halide_cmake_build_steps(factory, llvm_branch, os, configs)

    # Make and upload a distro
    factory.addStep(RemoveDirectory(dir='distrib', haltOnFailure=False))
    factory.addStep(MakeDirectory(dir='distrib', haltOnFailure=False))
    factory.addStep(MakeDirectory(dir='distrib\\halide', haltOnFailure=False))
    for d in ['Release', 'Debug', 'include', 'tools', 'tutorial', 'tutorial\\figures']:
        factory.addStep(MakeDirectory(dir='distrib\\halide\\' + d, haltOnFailure=False))

    file_pairs = [
        ('..\\halide-build-Release\\bin\\Release\\Halide.dll', 'Release'),
        ('..\\halide-build-Release\\lib\\Release\\Halide.lib', 'Release'),
        ('..\\halide-build-Debug\\bin\\Debug\\Halide.dll', 'Debug'),
        ('..\\halide-build-Debug\\lib\\Debug\\Halide.lib', 'Debug'),
        ('..\\halide-build-Release\\include\\Halide.h', 'include'),
        ('..\\halide\\src\\runtime\\HalideRuntim*.h', 'include'),
        ('..\\halide\\src\\runtime\\HalideBuffer.h', 'include'),
        ('..\\halide\\tools\\mex_halide.m', 'tools'),
        ('..\\halide\\tools\\GenGen.cpp', 'tools'),
        ('..\\halide\\tools\\RunGen.h', 'tools'),
        ('..\\halide\\tools\\RunGenMain.cpp', 'tools'),
        ('..\\halide\\tools\\halide_benchmark.h', 'tools'),
        ('..\\halide\\tools\\halide_image.h', 'tools'),
        ('..\\halide\\tools\\halide_image_io.h', 'tools'),
        ('..\\halide\\tools\\halide_image_info.h', 'tools'),
        ('..\\halide\\tools\\halide_malloc_trace.h', 'tools'),
        ('..\\halide\\tools\\halide_trace_config.h', 'tools'),
        ('..\\halide\\tutorial\\images\\*.png', 'tutorial\\figures'),
        ('..\\halide\\tutorial\\figures\\*.gif', 'tutorial\\figures'),
        ('..\\halide\\tutorial\\figures\\*.jpg', 'tutorial\\figures'),
        ('..\\halide\\tutorial\\figures\\*.mp4', 'tutorial\\figures'),
        ('..\\halide\\tutorial\\*.cpp', 'tutorial'),
        ('..\\halide\\tutorial\\*.h', 'tutorial'),
        ('..\\halide\\tutorial\\*.sh', 'tutorial'),
        ('..\\halide-build-Release\\halide_config.*', '.'),
        ('..\\halide\\halide.cmake', '.'),
        ('..\\halide\\README*.md', '.')]
    for (file, dir) in file_pairs:
        factory.addStep(
            ShellCommand(name='Copying ' + file,
                         workdir='distrib',
                         command=['copy', file, 'halide\\' + dir + '\\']))

    factory.addStep(
        ShellCommand(name='Zipping distribution',
                     workdir='distrib',
                     command=['C:\\Program Files\\7-Zip\\7z.exe',
                              'a',
                              'halide.zip',
                              'halide']))

    factory.addStep(
        FileUpload(workersrc='halide.zip',
                   workdir='distrib',
                   mode=0o644,
                   masterdest=get_distrib_name))

    return factory


def create_cmake_factory(os, llvm_branch):
    factory = BuildFactory()
    add_get_source_steps(factory, llvm_branch)

    configs = ['Release']

    clean_llvm_rebuild = (llvm_branch == LLVM_TRUNK_BRANCH)
    add_llvm_steps(factory, llvm_branch, os, configs, clean_llvm_rebuild)

    add_halide_cmake_build_steps(factory, llvm_branch, os, configs)

    add_halide_cmake_test_steps(factory, llvm_branch, os, configs)

    return factory


def create_factory(os, llvm_branch, use_cmake):
    if os.startswith('win') and '-distro' in os:
        return create_win_distro_factory(os, llvm_branch)
    elif os.startswith('win') or use_cmake:
        return create_cmake_factory(os, llvm_branch)
    else:
        return create_make_factory(os, llvm_branch)


def create_builder(os, llvm_branch, use_cmake=False):
    factory = create_factory(os, llvm_branch, use_cmake)

    tags = os.split('-')
    tags.append('llvm-' + to_name(llvm_branch))
    if 'testbranch' not in tags:
        tags.append('master')

    workers = get_workers(os)
    # TODO: brutal hack, linuxbots don't have enough space.
    # divide work between them for now.
    if 'linux-worker-2' in workers or 'linux-worker-3' in workers:
        # send trunk builds to one, everything else to the other
        if 'trunk' in to_name(llvm_branch):
            workers.remove('linux-worker-3')
        else:
            workers.remove('linux-worker-2')

    print("create_builder(%s, %s, %s) -> workers %s" %
          (str(os), str(llvm_branch), str(use_cmake), str(workers)))
    builder = BuilderConfig(name=os + '-' + to_name(llvm_branch),
                            workernames=workers,
                            factory=factory,
                            collapseRequests=True,
                            tags=tags)

    builder.llvm_branch = llvm_branch
    builder.os = os

    c['builders'].append(builder)


def create_scheduler(llvm_branch):

    def master_only(change):
        assert 'llvm' not in change.repository
        return change.branch == 'master' or change.branch is None

    def not_master(change):
        assert 'llvm' not in change.repository
        return not master_only(change)

    builders = []
    testbranch_builders = []

    for b in c['builders']:
        if b.llvm_branch != llvm_branch:
            continue
        if 'testbranch' in b.name:
            testbranch_builders.append(b.name)
        else:
            builders.append(b.name)

    # Quoth the buildbot docs:
    #
    # "The behavior of [SingleBranchScheduler] is undefined, if treeStableTimer is set,
    # and changes from multiple branches, repositories or codebases are accepted by the filter."
    #
    if len(builders):
        c['schedulers'].append(SingleBranchScheduler(
            name='halide-' + to_name(llvm_branch),
            codebases=['halide'],
            change_filter=util.ChangeFilter(filter_fn=master_only),
            treeStableTimer=60 * 5,  # seconds
            builderNames=builders))

    if len(testbranch_builders):
        c['schedulers'].append(SingleBranchScheduler(
            name='halide-testbranch-' + to_name(llvm_branch),
            codebases=['halide'],
            change_filter=util.ChangeFilter(filter_fn=not_master),
            treeStableTimer=60 * 5,  # seconds
            builderNames=testbranch_builders))

    c['schedulers'].append(ForceScheduler(
        name='force-' + to_name(llvm_branch),
        builderNames=[str(b.name) for b in c['builders'] if b.llvm_branch == llvm_branch],
        codebases=['halide', 'llvm']))

c['builders'] = []

# Builders that test master. We test the most recent official release
# of llvm on everything, to make it possible to do binary
# distributions with a uniform llvm version. We also test against llvm
# trunk, with lower priority, so that we can bisect llvm trunk
# breakages on various platforms if they are discovered late.
create_builder('arm32-linux-32', LLVM_TRUNK_BRANCH)
create_builder('arm32-linux-32', LLVM_OLD_BRANCH)

create_builder('arm64-linux-64', LLVM_TRUNK_BRANCH)
create_builder('arm64-linux-64', LLVM_OLD_BRANCH)

create_builder('linux-32-gcc53', LLVM_TRUNK_BRANCH)
create_builder('linux-32-gcc53', LLVM_RELEASE_BRANCH)
create_builder('linux-32-gcc53', LLVM_OLD_BRANCH)

create_builder('linux-64-gcc53', LLVM_TRUNK_BRANCH)
create_builder('linux-64-gcc53', LLVM_RELEASE_BRANCH)
create_builder('linux-64-gcc53', LLVM_OLD_BRANCH)

create_builder('mac-64', LLVM_TRUNK_BRANCH)
create_builder('mac-64', LLVM_RELEASE_BRANCH)
create_builder('mac-64', LLVM_OLD_BRANCH)

create_builder('win-32', LLVM_TRUNK_BRANCH)
create_builder('win-64', LLVM_TRUNK_BRANCH)

create_builder('win-32-distro', LLVM_RELEASE_BRANCH)
create_builder('win-64-distro', LLVM_RELEASE_BRANCH)

# Make some builders just for testing branches. Picking a fixed llvm
# version will avoid LLVM rebuilds for the best turnaround. Usually the
# most recent 'released' (non-trunk) version is the best choice.
create_builder('win-64-testbranch',         LLVM_RELEASE_BRANCH)
create_builder('win-32-testbranch',         LLVM_RELEASE_BRANCH)
create_builder('mac-64-testbranch',         LLVM_RELEASE_BRANCH)
create_builder('linux-64-gcc53-testbranch', LLVM_RELEASE_BRANCH)
create_builder('linux-32-gcc53-testbranch', LLVM_RELEASE_BRANCH)
create_builder('arm64-linux-64-testbranch', LLVM_RELEASE_BRANCH)
create_builder('arm32-linux-32-testbranch', LLVM_RELEASE_BRANCH)

# And some CMake testing
create_builder('mac-64-testbranch-cmake',         LLVM_RELEASE_BRANCH, use_cmake=True)
create_builder('linux-64-gcc53-testbranch-cmake', LLVM_RELEASE_BRANCH, use_cmake=True)
create_builder('linux-32-gcc53-testbranch-cmake', LLVM_RELEASE_BRANCH, use_cmake=True)
create_builder('arm64-linux-64-testbranch-cmake', LLVM_RELEASE_BRANCH, use_cmake=True)
create_builder('arm32-linux-32-testbranch-cmake', LLVM_RELEASE_BRANCH, use_cmake=True)

# Check for build breakages against other llvm versions too
create_builder('linux-64-gcc53-testbranch', LLVM_OLD_BRANCH)
create_builder('linux-64-gcc53-testbranch', LLVM_TRUNK_BRANCH)

c['schedulers'] = []
create_scheduler(LLVM_TRUNK_BRANCH)
create_scheduler(LLVM_RELEASE_BRANCH)
create_scheduler(LLVM_OLD_BRANCH)

# Create a scheduler to force a test of a branch
builders = [str(b.name) for b in c['builders'] if 'testbranch' in b.name]
scheduler = ForceScheduler(
    name='testbranch',
    builderNames=builders,
    codebases=['halide', 'llvm'])
c['schedulers'].append(scheduler)

# Set the builder priorities


def prioritize_builders(master, builders):
    def importance(builder):
        # Branch testers all need to come back before we can merge a PR,
        # so they all have equal highest priority.
        if 'testbranch' in builder.name:
            return 0

        # non-branch testers are mostly used for bisecting failures that
        # didn't show up in the branch testers and doing binary
        # releases. We care most about the most recently-released llvm so
        # that we have a full set of builds for releases, then llvm trunk
        # for bisection, then older llvm versions.
        if to_name(LLVM_RELEASE_BRANCH) in builder.name:
            return 1
        if to_name(LLVM_TRUNK_BRANCH) in builder.name:
            return 2
        if to_name(LLVM_OLD_BRANCH) in builder.name:
            return 3
        return 4

    builders.sort(key=importance)

    print("prioritize_builders:")
    for b in builders:
        print(("  PB: %s -> pri %d" % (b.name, importance(b))))

    return builders

c['prioritizeBuilders'] = prioritize_builders

# WEB SERVER

password = open('buildbot_www_pass.txt').read().strip()

authz = util.Authz(
    allowRules=[util.ForceBuildEndpointMatcher(role="admins"),
                util.StopBuildEndpointMatcher(role="admins"),
                util.RebuildBuildEndpointMatcher(role="admins"),
                util.EnableSchedulerEndpointMatcher(role="admins")],
    roleMatchers=[util.RolesFromUsername(roles=["admins"], usernames=["halidenightly"])])

c['www'] = dict(
    auth=util.UserPasswordAuth({'halidenightly': password}),
    authz=authz,
    port=8012,
)

# PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot
# installation's html.WebStatus home page (linked to the
# 'titleURL') and is embedded in the title of the waterfall HTML page.

c['title'] = 'Halide'
c['titleURL'] = 'http://halide-lang.org'

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server (usually the html.WebStatus page) is visible. This
# typically uses the port number set in the Waterfall 'status' entry, but
# with an externally-visible host name which the buildbot cannot figure out
# without some help.

c['buildbotURL'] = 'https://buildbot.halide-lang.org/master/'

# DB URL

c['db'] = {
    # This specifies what database buildbot uses to store its state.  You can leave
    # this at its default for all but the largest installations.
    'db_url': 'sqlite:///state.sqlite',
}

# GitHub Integration

from buildbot.plugins import reporters

builders = [str(b.name) for b in c['builders']]
gs = reporters.GitHubStatusPush(token=token,
                                context=Interpolate("buildbot/%(prop:buildername)s"),
                                startDescription='Build started.',
                                endDescription='Build done.',
                                verbose=True,
                                builders=builders)
c['services'] = [gs]
